{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3945acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverFactory\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from pyomo.core import * \n",
    "\n",
    "f_demand = Path(\"2050_Data/Consumption_2050.csv\")\n",
    "f_area_price = Path(\"2050_Data/Border_prices_2050.csv\")\n",
    "f_NTC = Path(\"2024_Data/NTC_BaseCase.csv\")                                           # Scenario-specific transfer capacity for base case scenario\n",
    "f_inflow = Path(\"2050_Data/Inflow_2050.csv\")\n",
    "f_k_energy = Path(\"2050_Data/K_energy_2050.csv\")\n",
    "f_k_prices = Path(\"2050_Data/K_prices_2050.csv\")\n",
    "f_loadshed = Path(\"2050_Data/Loadshedding_2050.csv\")\n",
    "f_elkjel = Path(\"2050_Data/Elkjel_2050.csv\")\n",
    "f_hydro = Path(\"2050_Data/Hydro_info_total_2050.csv\")\n",
    "f_energieq = Path(\"2050_Data/Energieq_2050.csv\")\n",
    "f_up_req = Path(\"2050_Data/Final_up_reserve_BaseCase.csv\")                             # Scenario-specific capacity reserve requirements for up-regulation\n",
    "f_down_req = Path(\"2050_Data/Final_down_reserve_BaseCase.csv\")                         # Scenario-specific capacity reserve requirements for down-regulation\n",
    "\n",
    "f_NO1_int = Path(\"2050_Intermittent/NO1_intermittent_energy.csv\")\n",
    "f_NO2_int = Path(\"2050_Intermittent/NO2_intermittent_energy.csv\")\n",
    "f_NO3_int = Path(\"2050_Intermittent/NO3_intermittent_energy.csv\")\n",
    "f_NO4_int = Path(\"2050_Intermittent/NO4_intermittent_energy.csv\")\n",
    "f_NO5_int = Path(\"2050_Intermittent/NO5_intermittent_energy.csv\")\n",
    "f_SE1_int = Path(\"2050_Intermittent/SE1_intermittent_energy.csv\")\n",
    "f_SE2_int = Path(\"2050_Intermittent/SE2_intermittent_energy.csv\")\n",
    "f_SE3_int = Path(\"2050_Intermittent/SE3_intermittent_energy.csv\")\n",
    "f_SE4_int = Path(\"2050_Intermittent/SE4_intermittent_energy.csv\")\n",
    "\n",
    "\n",
    "df_demand = pd.read_csv(f_demand, index_col=\"Timestamp\")\n",
    "df_area_price = pd.read_csv(f_area_price, index_col=\"Timestamp\")\n",
    "df_NTC = pd.read_csv(f_NTC, index_col=\"Area\")\n",
    "df_inflow = pd.read_csv(f_inflow, index_col=\"Timestamp\")\n",
    "df_k_energy = pd.read_csv(f_k_energy, index_col=\"Area\")\n",
    "df_k_prices = pd.read_csv(f_k_prices, index_col=\"Timestamp\")\n",
    "df_up_req = pd.read_csv(f_up_req, index_col=\"Timestamp\")\n",
    "df_down_req = pd.read_csv(f_down_req, index_col=\"Timestamp\")\n",
    "df_loadshed = pd.read_csv(f_loadshed, index_col=\"l\")\n",
    "df_loadshed.columns = df_loadshed.columns.str.strip()\n",
    "df_hydro = pd.read_csv(f_hydro, index_col=\"Area\")\n",
    "df_elkjel = pd.read_csv(f_elkjel, index_col=\"Area\")\n",
    "df_energieq = pd.read_csv(f_energieq, index_col=\"s\")\n",
    "\n",
    "df_int = {\n",
    "    \"NO1\": pd.read_csv(f_NO1_int, index_col=\"Timestamp\"),\n",
    "    \"NO2\": pd.read_csv(f_NO2_int, index_col=\"Timestamp\"),\n",
    "    \"NO3\": pd.read_csv(f_NO3_int, index_col=\"Timestamp\"),\n",
    "    \"NO4\": pd.read_csv(f_NO4_int, index_col=\"Timestamp\"),\n",
    "    \"NO5\": pd.read_csv(f_NO5_int, index_col=\"Timestamp\"),\n",
    "    \"SE1\": pd.read_csv(f_SE1_int, index_col=\"Timestamp\"),\n",
    "    \"SE2\": pd.read_csv(f_SE2_int, index_col=\"Timestamp\"),\n",
    "    \"SE3\": pd.read_csv(f_SE3_int, index_col=\"Timestamp\"),\n",
    "    \"SE4\": pd.read_csv(f_SE4_int, index_col=\"Timestamp\"),\n",
    "}\n",
    "\n",
    "\n",
    "step = 1\n",
    "T = list(df_demand.index.to_numpy()[::step])\n",
    "N = df_demand.columns.tolist()\n",
    "J =  df_int[\"NO1\"].columns.tolist()\n",
    "M = df_NTC.columns.tolist()\n",
    "K = df_k_energy.columns.tolist()\n",
    "S = df_energieq.index.tolist()\n",
    "\n",
    "X_t_n_j = {(t,n,j): df_int[n].at[t, j] for n in N for j in J for t in T}                                    # Produksjon fra intermittent\n",
    "X_cap_n_k = {(n,k): df_k_energy.loc[n,k] for n in N for k in K}                                             # Installert effekt for k energikilde\n",
    "\n",
    "X_cap_n_i = {n: df_hydro.loc[n, \"Installert effekt [MW]\"] for n in N}                                       # Installert effekt\n",
    "W_start_n_i = {n: df_hydro.loc[n, \"Start nivaa [MW]\"] for n in N}                                           # Start niv책 reservoir\n",
    "W_cap_n_i = {n: df_hydro.loc[n, \"Maks magasinfylling [MWh]\"] for n in N}                                    # Maks magasinnivb책\n",
    "W_inflow_t_n_i = {(t, n): df_inflow.loc[t, n]  for t in T for n in N}                                       # Inflow til hver generator i hvert omr책de\n",
    "\n",
    "Elkjel_cap = {n: df_elkjel.loc[n, \"Installert effekt [MW]\"] for n in N}                                     # Installed capacity for electric water heaters \n",
    "\n",
    "D_t_n = {(t,n): df_demand.loc[t,n] for t in T for n in N }                                                  # Demand til hvert omr책de\n",
    "\n",
    "Q_capacity = {                                                                                              # Net transfer capacity for mxm areas \n",
    "    (i, j): df_NTC.loc[i, j]\n",
    "    for i in M\n",
    "    for j in M\n",
    "}\n",
    "\n",
    "C_t_m = {(t, m): df_area_price.loc[t, m] for t in T for m in M}                                             # Prices for neighbouring areas \n",
    "C_t_k = {(t,k): df_k_prices.loc[t,k] for t in T for k in K}                                                 # Prices for k energy sources\n",
    "\n",
    "R_up_t_n = {(t,n): df_up_req.loc[t,n] for t in T for n in N}                                                # Reserve req for up regulation in each area\n",
    "R_down_t_n = {(t,n): df_down_req.loc[t,n] for t in T for n in N}                                            # Reserve req for down regulation in each area                                                \n",
    "                                                                    \n",
    "\n",
    "\" Data for energy eqivalent: \"\n",
    "\n",
    "A = df_energieq[\"A\"].to_dict()                                                                              # Alfa in %\n",
    "B = df_energieq[\"eeq\"].to_dict()                                                                            # Eeq in %\n",
    "\n",
    "                                                     \n",
    "\"Hardkoding for loadshed:\"\n",
    "\n",
    "L_max_l1 = 200\n",
    "L_max_l2 = 200\n",
    "L_max_l3 = 200\n",
    "L_max_l4 = 200\n",
    "L_max_l5 = 3200\n",
    "\n",
    "C_shed_l1 = 120\n",
    "C_shed_l2 = 300\n",
    "C_shed_l3 = 750\n",
    "C_shed_l4 = 1900\n",
    "C_shed_l5 = 4970   \n",
    "\n",
    "C_slack_up = 1000\n",
    "C_slack_down = 1000\n",
    "C_slack_energy = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create pyomo model, and defining sets, parameters and variables ----- \n",
    "\n",
    "model = pyo.ConcreteModel()\n",
    "\n",
    "\"-------- SETS -----------------------\"\n",
    "model.t = pyo.Set(initialize=T)\n",
    "model.j = pyo.Set(initialize=J)\n",
    "model.n = pyo.Set(initialize=N)\n",
    "model.m = pyo.Set(initialize=M)\n",
    "model.k = pyo.Set(initialize=K)\n",
    "model.s = pyo.Set(initialize=S)\n",
    "\n",
    "\"------- PARAMETERS ------------------\"\n",
    "model.X_t_n_j = pyo.Param(model.t, model.n, model.j, initialize = X_t_n_j)\n",
    "model.X_cap_n_i = pyo.Param(model.n, initialize = X_cap_n_i)\n",
    "model.X_cap_n_k = pyo.Param(model.n, model.k, initialize = X_cap_n_k)\n",
    "model.W_start_n_i = pyo.Param(model.n, initialize = W_start_n_i)\n",
    "model.W_cap_n_i = pyo.Param(model.n, initialize = W_cap_n_i)\n",
    "model.W_inflow_t_n_i = pyo.Param(model.t, model.n, initialize = W_inflow_t_n_i)\n",
    "model.D_t_n = pyo.Param(model.t, model.n, initialize = D_t_n)\n",
    "model.Q_capacity_m_n = pyo.Param(model.m, model.m, initialize = Q_capacity)\n",
    "model.C_t_m = pyo.Param(model.t, model.m, initialize = C_t_m)\n",
    "model.C_t_k = pyo.Param(model.t, model.k, initialize = C_t_k)\n",
    "model.R_up_t_n = pyo.Param(model.t, model.n, initialize = R_up_t_n)\n",
    "model.R_down_t_n = pyo.Param(model.t, model.n, initialize = R_down_t_n)\n",
    "model.Elkjel_n = pyo.Param(model.n, initialize = Elkjel_cap )\n",
    "model.A = pyo.Param(model.s, initialize=A)\n",
    "model.B = pyo.Param(model.s, initialize=B)\n",
    "\n",
    "C_elkjel = 30\n",
    "\n",
    "\"-------- VARIABLES ----------------------\"\n",
    "model.x_t_n_i = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.x_t_n_k = pyo.Var(model.t, model.n, model.k, within = pyo.NonNegativeReals)\n",
    "model.v_t_n_i = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.x_spill_t_n_j = pyo.Var(model.t, model.n, model.j, within = pyo.NonNegativeReals)\n",
    "model.w_spill_t_n_i = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.w_t_n_i = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.elkjel = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.q_flow_t_m_n = pyo.Var(model.t, model.m, model.m, within = pyo.NonNegativeReals)\n",
    "model.r_up_t_n_i = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.r_up_t_n_k = pyo.Var(model.t, model.n, model.k, within = pyo.NonNegativeReals)\n",
    "model.r_down_t_n_i = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.r_down_t_n_k = pyo.Var(model.t, model.n, model.k, within = pyo.NonNegativeReals)\n",
    "model.r_down_t_n_ror = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.r_down_t_n_elkjel = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.l1 = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.l2 = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.l3 = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.l4 = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.l5 = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.x_frac_t_n = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.v_frac_t_n = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.slack_up = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.slack_down = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)\n",
    "model.slack_energy = pyo.Var(model.t, model.n, within = pyo.NonNegativeReals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" -------  Defining constraints and objective function -------  \"\"\"\n",
    "\n",
    "# -------- Objective function -----------------\n",
    "def OBJ(model):\n",
    "    return sum(\n",
    "        sum(\n",
    "            sum(\n",
    "                model.C_t_m[t, m] * model.q_flow_t_m_n[t, m, n]    # Cost for import from n to m\n",
    "                - model.C_t_m[t, m] * model.q_flow_t_m_n[t, n, m]  # Cost for export from n to m\n",
    "                for m in model.m\n",
    "            )\n",
    "        \n",
    "            + model.C_t_k[t, 'Nuclear']* model.x_t_n_k[t, n, 'Nuclear']\n",
    "            + model.C_t_k[t, 'Thermal'] * 2.22 * model.x_t_n_k[t, n, 'Thermal']\n",
    "            \n",
    "            + C_shed_l1 * model.l1[t,n] + C_shed_l2 * model.l2[t,n] + C_shed_l3 * model.l3[t,n] + C_shed_l4 * model.l4[t,n] + C_shed_l5 * model.l5[t,n]  \n",
    "            \n",
    "            - C_elkjel * model.elkjel[t,n]\n",
    "\n",
    "            + model.C_t_k[t, 'Nuclear'] * 0.1 * (model.r_up_t_n_k[t, n, 'Nuclear'] - model.r_down_t_n_k[t, n, 'Nuclear'])\n",
    "            + model.C_t_k[t, 'Thermal'] * 2.22 * 0.1 * (model.r_up_t_n_k[t, n, 'Thermal'] - model.r_down_t_n_k[t, n, 'Thermal'])\n",
    "\n",
    "            + C_slack_up * model.slack_up[t,n] + C_slack_down * model.slack_down[t,n] + C_slack_energy * model.slack_energy[t,n]\n",
    "\n",
    "            for n in model.n\n",
    "        )\n",
    "        for t in model.t\n",
    "    )\n",
    "model.OBJ = pyo.Objective(rule=OBJ, sense=pyo.minimize)\n",
    "\n",
    "\n",
    "# ------   Energy balance  ---------- #\n",
    "def energy_balance(model, t, n):\n",
    "    return (\n",
    "        model.x_t_n_i[t, n]\n",
    "        + sum(model.x_t_n_k[t, n, k] for k in model.k)\n",
    "        + sum(model.X_t_n_j[t, n, j] - model.x_spill_t_n_j[t, n, j] for j in model.j)\n",
    "        + sum(model.q_flow_t_m_n[t, m, n] for m in model.m) # Import\n",
    "        - sum(model.q_flow_t_m_n[t, n, m] for m in model.m) # Export\n",
    "        + model.l1[t,n] + model.l2[t,n] + model.l3[t,n] + model.l4[t,n] + model.l5[t,n] \n",
    "        - model.elkjel[t,n]\n",
    "        + model.slack_energy[t,n]\n",
    "    ) == model.D_t_n[t, n]\n",
    "model.energy_balance = pyo.Constraint(model.t, model.n, rule=energy_balance)\n",
    "\n",
    "\n",
    "# ------ Reserve requirements constraints --------- Scenario-specific requirements are given to the model --------------#\n",
    "def reserve_cap_up(model, t, n):\n",
    "    return (model.r_up_t_n_i[t,n]  + \n",
    "        sum(model.r_up_t_n_k[t,n,k] for k in model.k) + model.slack_up[t,n] >= model.R_up_t_n[t,n]\n",
    "    )\n",
    "model.reserve_cap_up = pyo.Constraint(model.t, model.n, rule = reserve_cap_up)\n",
    "\n",
    "def reserve_cap_down(model, t, n):\n",
    "    return( model.r_down_t_n_i[t,n] + \n",
    "        sum(model.r_down_t_n_k[t,n,k] for k in model.k) \n",
    "        + model.r_down_t_n_ror[t,n] + model.r_down_t_n_elkjel[t,n] + model.slack_down[t,n] == model.R_down_t_n[t,n]\n",
    "    )\n",
    "model.reserve_cap_down = pyo.Constraint(model.t, model.n, rule = reserve_cap_down)\n",
    "\n",
    "\n",
    "# ------ Max production capacity constraints ------------ #\n",
    "\n",
    "def max_prod_i(model, t, n):\n",
    "    return model.v_t_n_i[t,n] + model.r_up_t_n_i[t,n] <= model.X_cap_n_i[n]\n",
    "model.max_prod_i = pyo.Constraint(model.t, model.n, rule=max_prod_i)\n",
    "\n",
    "\n",
    "def max_prod_k(model, t, n, k):\n",
    "    return model.x_t_n_k[t,n,k] + model.r_up_t_n_k[t,n,k] <= model.X_cap_n_k[n,k]\n",
    "model.max_prod_k = pyo.Constraint(model.t, model.n, model.k, rule = max_prod_k)\n",
    "\n",
    "def max_spill_j(model, t, n, j):\n",
    "    return model.x_spill_t_n_j[t,n,j] <= model.X_t_n_j[t,n,j]\n",
    "model.max_spill_j = pyo.Constraint(model.t, model.n, model.j, rule = max_spill_j)\n",
    "\n",
    "def max_shed(model, t, n):\n",
    "    return model.l1[t,n] + model.l2[t,n] + model.l3[t,n] + model.l4[t,n] + model.l5[t,n] <= model.D_t_n[t,n]\n",
    "model.max_shed = pyo.Constraint(model.t, model.n, rule = max_shed)\n",
    "\n",
    "def max_elkjel(model, t, n):\n",
    "    return model.elkjel[t,n] + model.r_down_t_n_elkjel[t,n] <= model.Elkjel_n[n]\n",
    "model.max_elkjel = pyo.Constraint(model.t, model.n, rule = max_elkjel)\n",
    "\n",
    "def max_ror_down(model, t, n):\n",
    "    return model.r_down_t_n_ror[t,n] <= model.X_t_n_j[t,n,'Run_of_river'] * 0.15\n",
    "model.max_ror_down = pyo.Constraint(model.t, model.n, rule = max_ror_down)\n",
    "\n",
    "# -------  Minimum production constraints ------------------\n",
    "def min_prod_i(model, t, n):\n",
    "    return model.r_down_t_n_i[t,n] <= model.x_t_n_i[t,n]\n",
    "model.min_prod_i = pyo.Constraint(model.t, model.n, rule = min_prod_i)   \n",
    "\n",
    "def min_prod_k(model, t, n, k):\n",
    "    return model.r_down_t_n_k[t,n,k] <= model.x_t_n_k[t,n,k]\n",
    "model.min_prod_k = pyo.Constraint(model.t, model.n, model.k, rule = min_prod_k)   \n",
    "\n",
    "\n",
    "# ------- Load shedding constraints ------------------------------\n",
    "def loadshed_max_l1(model, t, n):\n",
    "    return model.l1[t,n] <= L_max_l1\n",
    "model.loadshed_max_l1 = pyo.Constraint(model.t, model.n, rule = loadshed_max_l1)\n",
    "\n",
    "def loadshed_max_l2(model, t, n):\n",
    "    return model.l2[t,n] <= L_max_l2\n",
    "model.loadshed_max_l2 = pyo.Constraint(model.t, model.n, rule = loadshed_max_l2)\n",
    "\n",
    "def loadshed_max_l3(model, t, n):\n",
    "    return model.l3[t,n] <= L_max_l3\n",
    "model.loadshed_max_l3 = pyo.Constraint(model.t, model.n, rule = loadshed_max_l3)\n",
    "\n",
    "def loadshed_max_l4(model, t, n):\n",
    "    return model.l4[t,n] <= L_max_l4\n",
    "model.loadshed_max_l4 = pyo.Constraint(model.t, model.n, rule = loadshed_max_l4)\n",
    "\n",
    "def loadshed_max_l5(model, t, n):\n",
    "    return model.l5[t,n] <= L_max_l5\n",
    "model.loadshed_max_l5 = pyo.Constraint(model.t, model.n, rule = loadshed_max_l5)\n",
    "\n",
    "\n",
    "\n",
    "# ------  Transfer limits constraint with scenario-sepcific transfer capacities for base case scenario -----------------------\"\"\n",
    "def flow_capacity(model, t, i, j):\n",
    "    return model.q_flow_t_m_n[t,i,j] <= model.Q_capacity_m_n[i,j]                 \n",
    "   \n",
    "model.flow_capacity = pyo.Constraint(model.t, model.m, model.m, rule = flow_capacity)\n",
    "\n",
    "\n",
    "# ---------  Reservoir balance constraints -------------------------\n",
    "def reservoir_balance(model, t, n):\n",
    "    if t == model.t.first():\n",
    "        return model.w_t_n_i[t,n] == model.W_start_n_i[n] + model.W_inflow_t_n_i[t,n] - model.v_t_n_i[t,n] - model.w_spill_t_n_i[t,n] - 0.1*model.r_up_t_n_i[t,n] + 0.1*model.r_down_t_n_i[t,n]\n",
    "    else:\n",
    "        return model.w_t_n_i[t,n] == model.w_t_n_i[t-step,n] + model.W_inflow_t_n_i[t,n] - model.v_t_n_i[t,n] - model.w_spill_t_n_i[t,n] - 0.1*model.r_up_t_n_i[t,n] + 0.1*model.r_down_t_n_i[t,n]\n",
    "        \n",
    "model.reservoir_balance = pyo.Constraint(model.t, model.n, rule = reservoir_balance)\n",
    "\n",
    "def reservoir_level_end(model, n):\n",
    "    t_end = model.t.last()\n",
    "    return model.w_t_n_i[t_end, n] == model.W_start_n_i[n]\n",
    "model.reservoir_level_end = pyo.Constraint(model.n, rule=reservoir_level_end)\n",
    "\n",
    "def reservoir_level_max(model, t, n):\n",
    "    return model.w_t_n_i[t, n] <= model.W_cap_n_i[n]\n",
    "model.reservoir_level_max = pyo.Constraint(model.t, model.n, rule = reservoir_level_max)\n",
    "\n",
    "\n",
    "# ----------- Energy equivalent constraints --------------------------\n",
    "\n",
    "def scale_x(model, t, n):\n",
    "    return model.x_t_n_i[t,n] == model.x_frac_t_n[t,n] * model.X_cap_n_i[n]\n",
    "model.scale_x = pyo.Constraint(model.t, model.n, rule  = scale_x)\n",
    "\n",
    "def scale_v(model, t, n):\n",
    "    return model.v_t_n_i[t,n] == model.v_frac_t_n[t,n] * model.X_cap_n_i[n]\n",
    "model.scale_v = pyo.Constraint(model.t, model.n, rule = scale_v)\n",
    "\n",
    "def SegmentHydro(model, t, n, s):\n",
    "    return model.x_frac_t_n[t, n] <= model.A[s] + model.B[s] * model.v_frac_t_n[t, n] \n",
    "model.HydroSegmentConstr = pyo.Constraint(model.t, model.n, model.s, rule=SegmentHydro)\n",
    "\n",
    "def MaxV(model, t, n):\n",
    "    return  model.v_t_n_i[t, n] <= model.X_cap_n_i[n]\n",
    "model.MaxV = pyo.Constraint(model.t, model.n, rule = MaxV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT)\n",
    "with SolverFactory('gurobi', solver_io=\"python\") as opt:\n",
    "    results = opt.solve(model, load_solutions = True, tee = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868679cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Results from variables -------------------\n",
    "\n",
    "x_t_n_i_results = [(t, n, pyo.value(model.x_t_n_i[t, n])) for t in model.t for n in model.n]\n",
    "df_results_x_t_n_i = pd.DataFrame(list(x_t_n_i_results), columns=['Timestamp', 'Area', 'x_t_n_i_value']).set_index('Timestamp')\n",
    "\n",
    "x_t_n_k_results = [(t, n, k, pyo.value(model.x_t_n_k[t, n, k])) for t in model.t for n in model.n for k in model.k]\n",
    "df_results_x_t_n_k = pd.DataFrame(list(x_t_n_k_results), columns=['Timestamp', 'Area', 'Type', 'x_t_n_k_value']).set_index('Timestamp')\n",
    "\n",
    "v_t_n_i_results = [(t, n, pyo.value(model.v_t_n_i[t, n])) for t in model.t for n in model.n]\n",
    "df_results_v_t_n_i = pd.DataFrame(list(v_t_n_i_results), columns=['Timestamp', 'Area', 'x_t_n_i_value']).set_index('Timestamp')\n",
    "\n",
    "x_spill_t_n_j =  [(t, n, j, pyo.value(model.x_spill_t_n_j[t, n, j])) for t in model.t for n in model.n for j in model.j]\n",
    "df_results_x_spill_t_n_j = pd.DataFrame(list(x_spill_t_n_j), columns=['Timestamp', 'Area', 'Type', 'x_spill_t_n_j']).set_index('Timestamp')\n",
    "\n",
    "w_spill_t_n_i =  [(t, n, pyo.value(model.w_spill_t_n_i[t, n])) for t in model.t for n in model.n]\n",
    "df_results_w_spill_t_n_i = pd.DataFrame(list(w_spill_t_n_i), columns=['Timestamp', 'Area', 'w_spill_t_n_i']).set_index('Timestamp')\n",
    "\n",
    "w_t_n_i =  [(t, n, pyo.value(model.w_t_n_i[t, n])) for t in model.t for n in model.n]\n",
    "df_results_w_t_n_i = pd.DataFrame(list(w_t_n_i), columns=['Timestamp', 'Area', 'w_t_n_i']).set_index('Timestamp')\n",
    "\n",
    "loadshed_results = [(t, n, pyo.value(model.l1[t, n]), pyo.value(model.l2[t, n]), pyo.value(model.l3[t, n]), pyo.value(model.l4[t, n]), pyo.value(model.l5[t, n])) \n",
    "    for t in model.t for n in model.n]\n",
    "df_results_loadshed = pd.DataFrame(loadshed_results, columns=['Timestamp', 'Area', 'L1', 'L2', 'L3', 'L4', 'L5']).set_index('Timestamp')\n",
    "\n",
    "\n",
    "q_flow_t_m_n = [(t, i, j, pyo.value(model.q_flow_t_m_n[t, i, j])) for t in model.t for i in model.m for j in model.m]\n",
    "df_results_q_flow_t_m_n = pd.DataFrame(q_flow_t_m_n, columns=['Timestamp', 'From_node', 'To_node', 'q_import_t_m_n']).set_index('Timestamp')\n",
    "\n",
    "r_up_t_n_i = [(t, n, pyo.value(model.r_up_t_n_i[t, n])) for t in model.t for n in model.n]\n",
    "df_results_r_up_t_n_i = pd.DataFrame(list(r_up_t_n_i), columns=['Timestamp', 'Area', 'r_up_t_n_i']).set_index('Timestamp')\n",
    "\n",
    "\n",
    "r_up_t_n_k = [(t, n, k, pyo.value(model.r_up_t_n_k[t, n, k])) for t in model.t for n in model.n for k in model.k]\n",
    "df_results_r_up_t_n_k = pd.DataFrame(list(r_up_t_n_k), columns=['Timestamp', 'Area', 'Type', 'r_up_t_n_k']).set_index('Timestamp')\n",
    "\n",
    "r_down_t_n_i = [(t, n, pyo.value(model.r_down_t_n_i[t, n])) for t in model.t for n in model.n]\n",
    "df_results_r_down_t_n_i = pd.DataFrame(list(r_down_t_n_i), columns=['Timestamp', 'Area', 'r_down_t_n_i']).set_index('Timestamp')\n",
    "\n",
    "\n",
    "r_down_t_n_k = [(t, n, k, pyo.value(model.r_down_t_n_k[t, n, k])) for t in model.t for n in model.n for k in model.k]\n",
    "df_results_r_down_t_n_k = pd.DataFrame(list(r_down_t_n_k), columns=['Timestamp', 'Area', 'Type', 'r_down_t_n_k']).set_index('Timestamp')\n",
    "\n",
    "r_down_t_n_ror = [(t, n, pyo.value(model.r_down_t_n_ror[t, n])) for t in model.t for n in model.n]\n",
    "df_results_r_down_t_n_ror = pd.DataFrame(list(r_down_t_n_ror), columns=['Timestamp', 'Area', 'r_down_t_n_ror']).set_index('Timestamp')\n",
    "\n",
    "r_down_t_n_elkjel = [(t, n, pyo.value(model.r_down_t_n_elkjel[t, n])) for t in model.t for n in model.n]\n",
    "df_results_r_down_t_n_elkjel = pd.DataFrame(list(r_down_t_n_elkjel), columns=['Timestamp', 'Area', 'r_down_t_n_elkjel']).set_index('Timestamp')\n",
    "\n",
    "elkjel =  [(t, n, pyo.value(model.elkjel[t, n])) for t in model.t for n in model.n]\n",
    "df_results_elkjel = pd.DataFrame(list(elkjel), columns=['Timestamp', 'Area', 'elkjel']).set_index('Timestamp')\n",
    "\n",
    "x_frac_results = [(t, n, pyo.value(model.x_frac_t_n[t, n])) for t in model.t for n in model.n]\n",
    "df_results_x_frac_t_n = pd.DataFrame(list(x_frac_results), columns=['Timestamp', 'Area', 'x_frac_t_n _value']).set_index('Timestamp')\n",
    "\n",
    "v_frac_results = [(t, n, pyo.value(model.v_frac_t_n[t, n])) for t in model.t for n in model.n]\n",
    "df_results_v_frac_t_n = pd.DataFrame(list(v_frac_results), columns=['Timestamp', 'Area', 'v_frac_t_n _value']).set_index('Timestamp')\n",
    "\n",
    "slack_up =  [(t, n, pyo.value(model.slack_up[t, n])) for t in model.t for n in model.n]\n",
    "df_results_slack_up = pd.DataFrame(list(slack_up), columns=['Timestamp', 'Area', 'slack_up']).set_index('Timestamp')\n",
    "\n",
    "slack_down =  [(t, n, pyo.value(model.slack_down[t, n])) for t in model.t for n in model.n]\n",
    "df_results_slack_down = pd.DataFrame(list(slack_down), columns=['Timestamp', 'Area', 'slack_down']).set_index('Timestamp')\n",
    "\n",
    "slack_energy =  [(t, n, pyo.value(model.slack_energy[t, n])) for t in model.t for n in model.n]\n",
    "df_results_slack_energy = pd.DataFrame(list(slack_energy), columns=['Timestamp', 'Area', 'slack_energy']).set_index('Timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Results from dual values ------------------\n",
    "\n",
    "\n",
    "up_reg_prices = [(t,n, model.dual[model.reserve_cap_up[t,n]]) for t in model.t for n in model.n]\n",
    "df_results_up_reg_prices = pd.DataFrame(list(up_reg_prices), columns=['Timestamp', 'Area', 'up_reg_prices']).set_index('Timestamp')\n",
    "\n",
    "down_reg_prices = [(t,n, model.dual[model.reserve_cap_down[t,n]]) for t in model.t for n in model.n]\n",
    "df_results_down_reg_prices = pd.DataFrame(list(down_reg_prices), columns=['Timestamp', 'Area', 'down_reg_prices']).set_index('Timestamp')\n",
    "\n",
    "dual_reservoir_balance = [(t,n, model.dual[model.reservoir_balance[t,n]]) for t in model.t for n in model.n]\n",
    "df_results_dual_reservoir_balance = pd.DataFrame(list(dual_reservoir_balance), columns=['Timestamp', 'Area', 'Dual reservoir']).set_index('Timestamp')\n",
    "\n",
    "lambda_price = [(t,n, model.dual[model.energy_balance[t,n]]) for t in model.t for n in model.n]\n",
    "df_results_lambda = pd.DataFrame(list(lambda_price), columns=['Timestamp', 'Area', 'Lambda']).set_index('Timestamp')\n",
    "\n",
    "dual_max_prod_i = [(t,n, model.dual[model.max_prod_i[t,n]]) for t in model.t for n in model.n]\n",
    "df_results_dual_maxprodi = pd.DataFrame(list(dual_max_prod_i), columns=['Timestamp', 'Area', 'dual_x_i']).set_index('Timestamp')\n",
    "\n",
    "dual_flow = [(t,m,n, model.dual[model.flow_capacity[t,m,n]]) for t in model.t for m in model.m for n in model.n if (m, n) in Q_capacity]\n",
    "df_results_dual_flow = pd.DataFrame(list(dual_flow), columns=['Timestamp', 'From_node', 'To_node', 'dual_flow']).set_index('Timestamp')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Create csv files for variabel and dual values results -------------\n",
    "\n",
    "def save_result_dataframes(output_folder):\n",
    "    for var_name, df in globals().items():\n",
    "        if isinstance(df, pd.DataFrame) and var_name.startswith(\"df_results_\"):\n",
    "            file_path = os.path.join(output_folder, f\"{var_name}_2050.csv\")\n",
    "            df.to_csv(file_path)\n",
    "            print(f\"Lagret {var_name} til {file_path}\")\n",
    "\n",
    "\n",
    "save_result_dataframes(Path(\"Results_2050_BaseCase\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
